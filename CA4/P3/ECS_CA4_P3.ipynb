{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "vJmkn1owm3vZ",
        "outputId": "e3e31b3d-f956-4845-cce0-d126f4574218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/datasets/metadata/datasnaek/youtube-new\n",
            "unzip:  cannot find or open youtube-new.zip, youtube-new.zip.zip or youtube-new.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q kaggle\n",
        "\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d datasnaek/youtube-new\n",
        "\n",
        "!unzip -q youtube-new.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDEGFmCDurWY",
        "outputId": "d4b15039-20b1-4ec0-dffb-0b4b4d02d71f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing pipeline_script.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile pipeline_script.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import os\n",
        "\n",
        "TEXTUAL_COLUMNS = [\"title\", \"tags\", \"description\"]\n",
        "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
        "EMBEDDING_DIM = 384\n",
        "OUTPUT_DIR = \"tmp/embeddings/\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "us_df = pd.read_csv(\"USvideos.csv\")\n",
        "us_df[\"country\"] = \"US\"\n",
        "\n",
        "ca_df = pd.read_csv(\"CAvideos.csv\")\n",
        "ca_df[\"country\"] = \"CA\"\n",
        "\n",
        "df = pd.concat([us_df, ca_df], ignore_index=True)\n",
        "\n",
        "print(f\"[EMBEDDING][INFO]: Loading model {EMBEDDING_MODEL}...\")\n",
        "model = SentenceTransformer(EMBEDDING_MODEL)\n",
        "\n",
        "def clean_tags(text):\n",
        "    return \" \".join(tag.replace('\"', '') for tag in str(text).split('|'))\n",
        "\n",
        "for col in TEXTUAL_COLUMNS:\n",
        "    print(f\"[EMBEDDING][INFO]: Embedding column '{col}'...\")\n",
        "    if col == \"tags\":\n",
        "        text_data = df[col].fillna(\"\").apply(clean_tags).tolist()\n",
        "    else:\n",
        "        text_data = df[col].fillna(\"\").astype(str).tolist()\n",
        "\n",
        "    emb = model.encode(text_data, show_progress_bar=True, batch_size=32)\n",
        "    emb_df = pd.DataFrame(emb, columns=[f\"{col}_emb_{i}\" for i in range(emb.shape[1])])\n",
        "    df = pd.concat([df.reset_index(drop=True), emb_df], axis=1)\n",
        "\n",
        "def count_tags_loop(tag_str):\n",
        "    if pd.isna(tag_str):\n",
        "        return 0\n",
        "    count = 0\n",
        "    for tag in tag_str.split(\"|\"):\n",
        "        if tag.strip() != \"\":\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "tag_counts = []\n",
        "for i in range(len(df)):\n",
        "    tag_counts.append(count_tags_loop(df.iloc[i][\"tags\"]))\n",
        "df[\"tag_count\"] = tag_counts\n",
        "\n",
        "publish_dates = []\n",
        "publish_hours = []\n",
        "for i in range(len(df)):\n",
        "    try:\n",
        "        dt = datetime.strptime(df.iloc[i][\"publish_time\"], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
        "        publish_dates.append(dt)\n",
        "        publish_hours.append(dt.hour)\n",
        "    except Exception:\n",
        "        publish_dates.append(pd.NaT)\n",
        "        publish_hours.append(np.nan)\n",
        "\n",
        "df[\"publish_time\"] = publish_dates\n",
        "df[\"publish_hour\"] = publish_hours\n",
        "\n",
        "for col in TEXTUAL_COLUMNS:\n",
        "    if col in df.columns:\n",
        "        del df[col]\n",
        "\n",
        "engagement_rates = []\n",
        "ratios = []\n",
        "for i in range(len(df)):\n",
        "    row = df.iloc[i]\n",
        "    views = row[\"views\"]\n",
        "    likes = row[\"likes\"]\n",
        "    dislikes = row[\"dislikes\"]\n",
        "    comments = row[\"comment_count\"]\n",
        "    engagement_rates.append((likes + dislikes + comments) / (views + 1))\n",
        "    ratios.append(likes / (dislikes + 1))\n",
        "df[\"engagement_rate\"] = engagement_rates\n",
        "df[\"like_dislike_ratio\"] = ratios\n",
        "\n",
        "unique_cats = sorted(df[\"category_id\"].dropna().unique())\n",
        "one_hot = []\n",
        "for i in range(len(df)):\n",
        "    row = []\n",
        "    for cat in unique_cats:\n",
        "        row.append(1 if df.iloc[i][\"category_id\"] == cat else 0)\n",
        "    one_hot.append(row)\n",
        "\n",
        "cat_df = pd.DataFrame(one_hot, columns=[f\"cat_{int(c)}\" for c in unique_cats])\n",
        "df = pd.concat([df.reset_index(drop=True), cat_df], axis=1)\n",
        "df = df.drop(columns=[\"category_id\"])\n",
        "\n",
        "bool_cols = [\"comments_disabled\", \"ratings_disabled\", \"video_error_or_removed\"]\n",
        "for col in bool_cols:\n",
        "    df[col] = [int(val) for val in df[col]]\n",
        "df = df.drop(columns=bool_cols)\n",
        "\n",
        "seen_rows = set()\n",
        "deduped_rows = []\n",
        "for i in range(len(df)):\n",
        "    row_tuple = tuple(df.iloc[i].values)\n",
        "    if row_tuple not in seen_rows:\n",
        "        seen_rows.add(row_tuple)\n",
        "        deduped_rows.append(df.iloc[i])\n",
        "df = pd.DataFrame(deduped_rows).reset_index(drop=True)\n",
        "\n",
        "numeric_attributes = [\n",
        "    \"views\", \"publish_hour\", \"likes\", \"dislikes\", \"comment_count\",\n",
        "    \"engagement_rate\", \"like_dislike_ratio\", \"tag_count\"\n",
        "]\n",
        "numeric_attributes += [col for col in df.columns if \"_emb_\" in col]\n",
        "\n",
        "for col in numeric_attributes:\n",
        "    transformed = []\n",
        "    for i in range(len(df)):\n",
        "        transformed.append(np.log1p(df.iloc[i][col]))\n",
        "    df[col] = transformed\n",
        "\n",
        "minmax_scaler = MinMaxScaler()\n",
        "scaled_minmax = minmax_scaler.fit_transform(df[numeric_attributes])\n",
        "for j, col in enumerate(numeric_attributes):\n",
        "    for i in range(len(df)):\n",
        "        df.at[i, col] = scaled_minmax[i][j]\n",
        "\n",
        "standard_scaler = StandardScaler()\n",
        "scaled_standard = standard_scaler.fit_transform(df[numeric_attributes])\n",
        "for j, col in enumerate(numeric_attributes):\n",
        "    for i in range(len(df)):\n",
        "        df.at[i, col] = scaled_standard[i][j]\n",
        "\n",
        "df = df.drop(columns=[\"likes\", \"dislikes\"])\n",
        "\n",
        "print(\"Preprocessing complete. Final shape:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1wXZfpqS6lw"
      },
      "outputs": [],
      "source": [
        "import cProfile\n",
        "import pstats\n",
        "\n",
        "cProfile.run(\"exec(open('pipeline_script.py').read())\", \"profile_results.prof\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stats = pstats.Stats(\"profile_results.prof\")\n",
        "stats.strip_dirs().sort_stats(\"cumulative\").print_stats(50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
